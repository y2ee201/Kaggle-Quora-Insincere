{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\nimport gc\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom math import sqrt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, log_loss\nfrom imblearn.under_sampling import RandomUnderSampler\nimport gc\nfrom keras.models import Model\nfrom keras.layers import Dense, Conv1D, Dropout, Input, GlobalAveragePooling1D, MaxPool1D, Flatten, LSTM",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dddad8e975599093c48b6eb245bf258b2b57bccf"
      },
      "cell_type": "code",
      "source": "questions = pd.read_csv('../input/train.csv')\nquestions.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "006c5f7591405823cdf00e80278d2dc1327eb444"
      },
      "cell_type": "code",
      "source": "os.listdir('../input/embeddings/')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b04985879793dd15d767a5b420811dc8ee825a89"
      },
      "cell_type": "code",
      "source": "max_len = 200",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e728bfdd0945d829b38adc19745ba7d8cfb911e"
      },
      "cell_type": "code",
      "source": "embeddings = dict()\n# file = open('../input/embeddings/glove.840B.300d/glove.840B.300d.txt', encoding='UTF-8')\nfile = open('../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec', \n            encoding='UTF-8')\nfor line in file:\n    values = line.split(\" \")\n    word, coefs  = values[0], np.array(values[1:], dtype='float32')\n    embeddings[word] = coefs",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "43d927edf77a069c6bae26d16206cbdd72ea4b21"
      },
      "cell_type": "code",
      "source": "tkn = Tokenizer()\ntkn.fit_on_texts(questions.question_text)\nvocab_size = len(tkn.word_index) + 1\nenc_sentence = tkn.texts_to_sequences(questions.question_text)\nenc_sentence = pad_sequences(enc_sentence, max_len)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fcecf47cdbf92509bdf0a519eb08aca5d53565f9"
      },
      "cell_type": "code",
      "source": "embed_matrix = np.zeros((vocab_size, 300))\nfor word, i in tkn.word_index.items():\n    vec = embeddings.get(word)\n    if(vec is not None):\n        embed_matrix[i] = vec",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ad552efe5e552521b450b54626a0ecaa148e567"
      },
      "cell_type": "code",
      "source": "sent_vecs = np.zeros((len(enc_sentence), 300))\nfor i in range(len(enc_sentence)):\n    word_vec = np.array([embed_matrix[w] for w in enc_sentence[i]])\n    sent_vec = np.sum(word_vec, axis=0)\n    sent_vec = sent_vec/sqrt((sent_vec**2).sum())\n    sent_vec = np.nan_to_num(sent_vec)\n    # sent_vec = sent_vec.reshape((300, 1))\n    sent_vecs[i] = sent_vec\nsent_vecs.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e0c3e96f351606f2896c0b8e74b5e85fea5f193"
      },
      "cell_type": "code",
      "source": "gc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e9f2468f4fbd04cd9ec104c2319bed674ae42cd9"
      },
      "cell_type": "code",
      "source": "rus = RandomUnderSampler(random_state=42)\nX_resampled, y_resampled = rus.fit_sample(sent_vecs, questions.target)\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, \n                                                    test_size = 0.2, random_state=42)\n# X_train, X_test, y_train, y_test = train_test_split(sent_vecs, questions.target, \n#                                                    test_size = 0.2, random_state=42)\nX_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\nX_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\nX_train.shape, X_test.shape, y_train.shape, y_test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c8fe7ae6384a9556e26539a904d6455e856bf7d"
      },
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X_test.reshape([X_test.shape[0], X_test.shape[1]]), y_test, \n                                                    test_size = 0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce45d68af4962baae13431fd35eceb0892e71f98"
      },
      "cell_type": "code",
      "source": "from sklearn.kernel_approximation import Nystroem\nfrom sklearn import svm\n\nclf = svm.LinearSVC(C=21.5443, tol=0.0001)\nfeature_map_nystroem = Nystroem(gamma=.0013, random_state=1234, n_components=500)\n\n# data_transformed = feature_map_nystroem.fit_transform(X_train)\n\nclf.fit(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d46b1053822d7b8eda7d2516ee6bd8471035f267"
      },
      "cell_type": "code",
      "source": "preds = clf.predict(X_val)\nf1_score(y_pred=preds, y_true=y_val), log_loss(y_pred=preds, y_true=y_val)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f7d02dc830f5dda47aa4fc8b39e06a2855c5b17"
      },
      "cell_type": "code",
      "source": "questions_test = pd.read_csv('../input/test.csv')\nquestions_test.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6b0c8a8de95754bc9358264e89aa4abacafaea8"
      },
      "cell_type": "code",
      "source": "enc_sentence_test = tkn.texts_to_sequences(questions_test.question_text)\nenc_sentence_test = pad_sequences(enc_sentence_test, max_len)\nlen(enc_sentence_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9cb043cd00e91d6449459b08e0b1f8d0e139d958"
      },
      "cell_type": "code",
      "source": "sent_vecs_test = np.zeros((len(enc_sentence_test), 300))\nfor i in range(len(enc_sentence_test)):\n    word_vec = np.array([embed_matrix[w] for w in enc_sentence_test[i]])\n    sent_vec = np.sum(word_vec, axis=0)\n    sent_vec = sent_vec/sqrt((sent_vec**2).sum())\n    sent_vec = np.nan_to_num(sent_vec)\n    # sent_vec = sent_vec.reshape((300, 1))\n    sent_vecs_test[i] = sent_vec\nsent_vecs_test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "54c8490814a06011bfd72f210afcd696a5b192c7"
      },
      "cell_type": "code",
      "source": "preds = clf.predict(sent_vecs_test)\nsubmission = pd.DataFrame({'qid': questions_test.qid, 'prediction':preds})\nsubmission.info()\nsubmission.to_csv('./submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d5d47e5bef2bc631e6c43cbe3405eab7565f931"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}